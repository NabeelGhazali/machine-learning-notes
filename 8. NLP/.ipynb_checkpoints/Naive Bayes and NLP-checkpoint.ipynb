{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cec91380",
   "metadata": {},
   "source": [
    "### NAIVE BAYES ALGORITHM - PART 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00dcf8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayes theorem is a probability formula that leverages previously known probabilities to define probability of the related events occuring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de07205",
   "metadata": {},
   "source": [
    "### NAIVE BAYES ALGORITHM - PART 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20268dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayes theoram to machien learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c10ef39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we assume that teh x features are mutually independant\n",
    "# when we extract features from a sentence which means words for a sentence\n",
    "# all teh words are not mutually independent\n",
    "# therefore it is a naive assumption that all words are mutualy independant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "759ea272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# many variations of Naive Bayes:\n",
    "#     multinomial\n",
    "#     gausian\n",
    "#     complement\n",
    "#     bernoulli\n",
    "#     categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ef141cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for NLP we will use multinoial naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ca33686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer means breaking down a sentence or any text into words by performing preprocessing tasks like converting all words to lowercase, thus removing special characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d2dde1",
   "metadata": {},
   "source": [
    "### EXTRACTING FEATURE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da11f3cc",
   "metadata": {},
   "source": [
    "##### THEORY AND INTUITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37d4bc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction from raw string text\n",
    "# from string to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14fc5226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main methods of feature extraction:\n",
    "# 1. count vectorization\n",
    "# 2. term frequency\n",
    "\n",
    "# count vectorization \n",
    "# counts every word in the document\n",
    "# stored in sparse matrix  to save space\n",
    "\n",
    "# DTM document term matrix\n",
    "\n",
    "# issues to consider:\n",
    "#     very common words\n",
    "#     words common to a particular set of documents (run in sports)\n",
    "#     stop words (a, the etc.)\n",
    "\n",
    "# we can address the issue of the document frequency by using a TF-IDF vectorization process\n",
    "# instead of filling the DTM with word frequency counts it calculates term frequency-inverse document frequency value for each word(TF-IDF)\n",
    "\n",
    "# term freq tf(t,d)\n",
    "# number of times that term t occurs in a document d\n",
    "\n",
    "# inverse doc freq factor is incorporated which diminishes the weight of terms that occur very frequently in the document set and increases the weight of terms that occur rarely\n",
    "# the idf is how common or rare a word is in the enire doc set\n",
    "# the closer it is to zero the more common a word is\n",
    "# calculated by taking the total number of doc, dividing it by the number of doc that contain a word and calculating the log\n",
    "# TF-IDF = term freq * (1/doc freq)\n",
    "\n",
    "# scikit learn have three ways of doing NLP by using API\n",
    "# count vectorization\n",
    "# TF-IDF transformer\n",
    "# TF-IDF vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34bc8b7",
   "metadata": {},
   "source": [
    "##### CODING COUNT VECTORIZATION MANUALLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c5ae4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
